{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYl9vHLKApuf"
   },
   "source": [
    "# CS-GY 9223-D: Deep Learning Homework 1\n",
    "Due on Friday, 15th February 2019, 11:55 PM\n",
    "\n",
    "This homework can be done in pairs. Everyone must submit on NYU Classes individually.\n",
    "\n",
    "Write down the UNIs (NetIDs) of your group (if applicable)\n",
    "\n",
    "Member 1: Hupo Tang, ht1073\n",
    "\n",
    "Member 2: YUAN TANG LIN, ytl329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_s6vogWApul"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5TQ6ipJApux"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUAlJ0OJApu0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vhNZ0ttApu9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform1 = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform2 = transforms.Compose(\n",
    "    [#transforms.RandomResizedCrop(32),\n",
    "     transforms.RandomHorizontalFlip(1),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset1 = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform1)\n",
    "trainset2 = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform2)\n",
    "\n",
    "trainset = torch.utils.data.ConcatDataset([trainset1,trainset2])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=20,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=20,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here extend training dataset to moreHorizontalFlip training dataset\n",
    "- Set batch size to 20 for higher performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjHC05KlApvD"
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDZC1qP0ApvF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.618\n",
      "[1,  4000] loss: 1.321\n",
      "[2,  2000] loss: 1.154\n",
      "[2,  4000] loss: 1.118\n",
      "[3,  2000] loss: 1.030\n",
      "[3,  4000] loss: 1.022\n",
      "[4,  2000] loss: 0.959\n",
      "[4,  4000] loss: 0.961\n",
      "[5,  2000] loss: 0.900\n",
      "[5,  4000] loss: 0.907\n",
      "[6,  2000] loss: 0.868\n",
      "[6,  4000] loss: 0.885\n",
      "[7,  2000] loss: 0.835\n",
      "[7,  4000] loss: 0.855\n",
      "[8,  2000] loss: 0.803\n",
      "[8,  4000] loss: 0.824\n",
      "[9,  2000] loss: 0.781\n",
      "[9,  4000] loss: 0.800\n",
      "[10,  2000] loss: 0.760\n",
      "[10,  4000] loss: 0.785\n",
      "[11,  2000] loss: 0.742\n",
      "[11,  4000] loss: 0.764\n",
      "[12,  2000] loss: 0.727\n",
      "[12,  4000] loss: 0.754\n",
      "[13,  2000] loss: 0.712\n",
      "[13,  4000] loss: 0.736\n",
      "[14,  2000] loss: 0.699\n",
      "[14,  4000] loss: 0.724\n",
      "[15,  2000] loss: 0.697\n",
      "[15,  4000] loss: 0.714\n",
      "[16,  2000] loss: 0.677\n",
      "[16,  4000] loss: 0.708\n",
      "[17,  2000] loss: 0.666\n",
      "[17,  4000] loss: 0.695\n",
      "[18,  2000] loss: 0.654\n",
      "[18,  4000] loss: 0.691\n",
      "[19,  2000] loss: 0.644\n",
      "[19,  4000] loss: 0.678\n",
      "[20,  2000] loss: 0.640\n",
      "[20,  4000] loss: 0.676\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#INPUT -> [CONV -> RELU -> POOL]*2 -> FC -> RELU -> FC\n",
    "#INPUT -> [CONV -> RELU -> CONV -> RELU -> POOL]*3 -> [FC -> RELU]*2 -> FC\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    '''def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.conv2 = nn.Conv2d(10, 40, 5)\n",
    "        self.conv3 = nn.Conv2d(40, 90, 5)\n",
    "        self.conv4 = nn.Conv2d(90, 190, 5)\n",
    "        self.conv5 = nn.Conv2d(190, 210, 1)\n",
    "        self.conv6 = nn.Conv2d(210, 250, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(250*1*1, 300)\n",
    "        self.fc2 = nn.Linear(300, 80)\n",
    "        self.fc3 = nn.Linear(80, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
    "        x = self.pool(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
    "        x = self.pool(F.relu(self.conv6(F.relu(self.conv5(x)))))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 250*1*1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = CNN()\n",
    "        \n",
    "#loss function\n",
    "loss = nn.CrossEntropyLoss()\n",
    " \n",
    "#optimizer = \n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "        running_loss = 0.0\n",
    "        for i,data in enumerate(trainloader,0):\n",
    "            #get the inputs\n",
    "            X,y  = data\n",
    "            #please ensure that the data is in the appropriate tensor form as required.\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            # backward pass\n",
    "            # optimize the weights\n",
    "            outputs = net(X)\n",
    "            loss2 = loss(outputs, y)\n",
    "            loss2.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics during training\n",
    "            running_loss += loss2.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "print('Finished Training')\n",
    "            \n",
    "#predict on the test data\n",
    "#save the predictions to ans2-uni.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here use Adam as a better optimizer\n",
    "- Calculate for epoch loop  20 times for better training\n",
    "- Set up convolution to 16 filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the Testcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 67 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    _y = []\n",
    "    for data in testloader:\n",
    "        X, y = data\n",
    "        outputs = net(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        p = list(predicted)\n",
    "        for _p in p:\n",
    "            _y.append(_p)\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,y in enumerate(_y):\n",
    "    _y[i] =str(int(y)).encode(\"utf-8\").decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ans2-uni.npy', mode='w')\n",
    "f.write(str(_y))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW1-CNN-uni.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
