{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-GY 9223-D: Deep Learning Homework 2\n",
    "Due on Friday, 12th March 2019, 11:55 PM\n",
    "\n",
    "This homework can be done in pairs.\n",
    "\n",
    "Write down the UNIs (NetIDs) of your group (if applicable)\n",
    "\n",
    "Member 1: Hupo Tang, ht1073\n",
    "\n",
    "Member 2: Name, NetID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda, Reshape\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout, Lambda, Reshape, ZeroPadding2D\n",
    "# from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import cv2\n",
    "# import matplotlib.pylab as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './'\n",
    "TRAIN = './images_training_rev1/'\n",
    "VALID = ''\n",
    "TEST = './images_test_rev1/'\n",
    "LABELS = './training_solutions_rev1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from scipy.misc import imresize\n",
    "import csv\n",
    "\n",
    "class data_loader:    \n",
    "    \"\"\"\n",
    "    Creates a class for handling train/valid/test data paths,\n",
    "    training labels and image IDs.\n",
    "    Useful for switching between sample and full datasets.\n",
    "    \"\"\"\n",
    "    def __init__(self, path):    \n",
    "        self.path = path \n",
    "        self.train_path = TRAIN\n",
    "        #self.val_path = path + \"valid\"\n",
    "        self.test_path = TEST\n",
    "        \n",
    "        def get_paths(directory):\n",
    "            return [f for f in os.listdir(directory)]\n",
    "        \n",
    "        self.training_images_paths = get_paths(self.train_path)\n",
    "        # self.validation_images_paths = get_paths(self.val_path)\n",
    "        self.test_images_paths = get_paths(self.test_path)    \n",
    "        \n",
    "        def get_all_solutions():\n",
    "        # Import solutions file and load into self.solutions\n",
    "            all_solutions = {}\n",
    "            # /'training_solutions_rev1.csv'\n",
    "            with open(LABELS, 'r') as f:\n",
    "                reader = csv.reader(f, delimiter=\",\")\n",
    "                next(reader)\n",
    "                for i, line in enumerate(reader):\n",
    "                    all_solutions[line[0]] = [float(x) for x in line[1:]]\n",
    "            return all_solutions\n",
    "        \n",
    "        self.all_solutions = get_all_solutions()\n",
    "\n",
    "    def get_id(self,fname):\n",
    "        return fname.replace(\".jpg\",\"\").replace(\"data\",\"\")\n",
    "        \n",
    "    def find_label(self,val):\n",
    "        return self.all_solutions[val]\n",
    "\n",
    "def process_images(paths):\n",
    "    \"\"\"\n",
    "    Import image at 'paths', decode, centre crop and prepare for batching. \n",
    "    \"\"\"\n",
    "    count = len(paths)\n",
    "    arr = np.zeros(shape=(count,3,106,106))\n",
    "    for c, path in enumerate(paths):\n",
    "        img = cv2.imread(path).T\n",
    "        img = img[:,106:106*3,106:106*3] #crop 424x424 -> 212x212\n",
    "        img = imresize(img,size=(106,106,3),interp=\"cubic\").T # downsample to half res\n",
    "        arr[c] = img\n",
    "    return arr\n",
    "\n",
    "def BatchGenerator(getter):\n",
    "    while 1:\n",
    "        for f in getter.training_images_paths:\n",
    "            X_train = process_images([getter.train_path + '/' + fname for fname in [f]])\n",
    "            id_ = getter.get_id(f)\n",
    "            y_train = np.array(getter.find_label(id_))\n",
    "            y_train = np.reshape(y_train,(1,37))\n",
    "            yield (X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img):\n",
    "    return np.rot90(img,axes=(1,2))\n",
    "\n",
    "def flip(img):\n",
    "    return np.flip(img, axis=1)            \n",
    "\n",
    "def process_withaug(paths,aug=0):\n",
    "    count = len(paths)\n",
    "    arr = np.zeros(shape=(count,3,106,106))\n",
    "    for c, path in enumerate(paths):\n",
    "        raw_img = cv2.imread(path).T\n",
    "        if not aug:\n",
    "            img=raw_img\n",
    "        else:\n",
    "            auger={1:rotate,2:flip}.get(aug)\n",
    "            img=auger(raw_img)\n",
    "        img = img[:,106:106*3,106:106*3] #crop 424x424 -> 212x212\n",
    "        img = imresize(img,size=(106,106,3),interp=\"cubic\").T # downsample to half res\n",
    "        arr[c] = img\n",
    "    return arr\n",
    "\n",
    "def BatchGenerator_withaug(getter):\n",
    "    while 1:\n",
    "        for f in getter.training_images_paths:\n",
    "            for aug in {0,1,2}:\n",
    "                X_train = process_withaug([getter.train_path + '/' + fname for fname in [f]], aug)\n",
    "                id_ = getter.get_id(f)\n",
    "                y_train = np.array(getter.find_label(id_))\n",
    "                y_train = np.reshape(y_train,(1,37))\n",
    "                yield (X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetcher = data_loader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(layers, model, filters):\n",
    "    \"\"\"\n",
    "    Create a layered Conv/Pooling block\n",
    "    \"\"\"\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1,1)))  # zero padding of size 1\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))  # 3x3 filter size \n",
    "    model.add(MaxPooling2D((1,1), strides=(2,2)))\n",
    "\n",
    "def FCBlock(model):\n",
    "    \"\"\"\n",
    "    Fully connected block with ReLU and dropout\n",
    "    \"\"\"\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "def VGG_16():\n",
    "    \"\"\"\n",
    "    Implement VGG16 architecture\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x : x, input_shape=(3,106,106)))\n",
    "    \n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "    \n",
    "    model.add(Dense(37, activation = 'sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile \n",
    "optimizer = RMSprop(lr=1e-6)\n",
    "model = VGG_16()\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "    \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath='./tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "batch_size = 32\n",
    "steps_to_take = int(len(fetcher.training_images_paths)/batch_size)\n",
    "\n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 67s - loss: 0.0969\n",
      "Epoch 2/50\n",
      " - 58s - loss: 0.0324\n",
      "Epoch 3/50\n",
      " - 60s - loss: 0.0314\n",
      "Epoch 4/50\n",
      " - 56s - loss: 0.0310\n",
      "Epoch 5/50\n",
      " - 61s - loss: 0.0299\n",
      "Epoch 6/50\n",
      " - 57s - loss: 0.0292\n",
      "Epoch 7/50\n",
      " - 60s - loss: 0.0292\n",
      "Epoch 8/50\n",
      " - 63s - loss: 0.0288\n",
      "Epoch 9/50\n",
      " - 61s - loss: 0.0284\n",
      "Epoch 10/50\n",
      " - 56s - loss: 0.0289\n",
      "Epoch 11/50\n",
      " - 70s - loss: 0.0281\n",
      "Epoch 12/50\n",
      " - 67s - loss: 0.0279\n",
      "Epoch 13/50\n",
      " - 71s - loss: 0.0279\n",
      "Epoch 14/50\n",
      " - 63s - loss: 0.0280\n",
      "Epoch 15/50\n",
      " - 62s - loss: 0.0278\n",
      "Epoch 16/50\n",
      " - 65s - loss: 0.0271\n",
      "Epoch 17/50\n",
      " - 63s - loss: 0.0269\n",
      "Epoch 18/50\n",
      " - 60s - loss: 0.0277\n",
      "Epoch 19/50\n",
      " - 64s - loss: 0.0267\n",
      "Epoch 20/50\n",
      " - 61s - loss: 0.0265\n",
      "Epoch 21/50\n",
      " - 62s - loss: 0.0265\n",
      "Epoch 22/50\n",
      " - 60s - loss: 0.0266\n",
      "Epoch 23/50\n",
      " - 60s - loss: 0.0273\n",
      "Epoch 24/50\n",
      " - 61s - loss: 0.0264\n",
      "Epoch 25/50\n",
      " - 67s - loss: 0.0256\n",
      "Epoch 26/50\n",
      " - 64s - loss: 0.0250\n",
      "Epoch 27/50\n",
      " - 59s - loss: 0.0246\n",
      "Epoch 28/50\n",
      " - 63s - loss: 0.0242\n",
      "Epoch 29/50\n",
      " - 67s - loss: 0.0243\n",
      "Epoch 30/50\n",
      " - 58s - loss: 0.0235\n",
      "Epoch 31/50\n",
      " - 66s - loss: 0.0230\n",
      "Epoch 32/50\n",
      " - 65s - loss: 0.0229\n",
      "Epoch 33/50\n",
      " - 65s - loss: 0.0231\n",
      "Epoch 34/50\n",
      " - 63s - loss: 0.0225\n",
      "Epoch 35/50\n",
      " - 63s - loss: 0.0224\n",
      "Epoch 36/50\n",
      " - 54s - loss: 0.0218\n",
      "Epoch 37/50\n",
      " - 54s - loss: 0.0218\n",
      "Epoch 38/50\n",
      " - 62s - loss: 0.0220\n",
      "Epoch 39/50\n",
      " - 59s - loss: 0.0223\n",
      "Epoch 40/50\n",
      " - 56s - loss: 0.0223\n",
      "Epoch 41/50\n",
      " - 55s - loss: 0.0222\n",
      "Epoch 42/50\n",
      " - 56s - loss: 0.0223\n",
      "Epoch 43/50\n",
      " - 57s - loss: 0.0219\n",
      "Epoch 44/50\n",
      " - 63s - loss: 0.0217\n",
      "Epoch 45/50\n",
      " - 54s - loss: 0.0214\n",
      "Epoch 46/50\n",
      " - 54s - loss: 0.0215\n",
      "Epoch 47/50\n",
      " - 55s - loss: 0.0214\n",
      "Epoch 48/50\n",
      " - 53s - loss: 0.0213\n",
      "Epoch 49/50\n",
      " - 57s - loss: 0.0209\n",
      "Epoch 50/50\n",
      " - 56s - loss: 0.0216\n"
     ]
    }
   ],
   "source": [
    "# VGG16 with no augmentation\n",
    "\n",
    "hist = model.fit_generator(BatchGenerator(fetcher),\n",
    "                    samples_per_epoch=steps_to_take, \n",
    "                    nb_epoch=50,\n",
    "                    verbose=2,\n",
    "                    callbacks=[history,checkpointer,early_stopping],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 117s - loss: 0.0219\n",
      "Epoch 2/25\n",
      " - 117s - loss: 0.0211\n",
      "Epoch 3/25\n",
      " - 118s - loss: 0.0205\n",
      "Epoch 4/25\n",
      " - 118s - loss: 0.0199\n",
      "Epoch 5/25\n",
      " - 119s - loss: 0.0199\n",
      "Epoch 6/25\n",
      " - 125s - loss: 0.0201\n",
      "Epoch 7/25\n",
      " - 120s - loss: 0.0200\n",
      "Epoch 8/25\n",
      " - 117s - loss: 0.0198\n",
      "Epoch 9/25\n",
      " - 118s - loss: 0.0195\n",
      "Epoch 10/25\n",
      " - 124s - loss: 0.0197\n",
      "Epoch 11/25\n",
      " - 130s - loss: 0.0190\n",
      "Epoch 12/25\n",
      " - 117s - loss: 0.0187\n",
      "Epoch 13/25\n",
      " - 117s - loss: 0.0186\n",
      "Epoch 14/25\n",
      " - 117s - loss: 0.0186\n",
      "Epoch 15/25\n",
      " - 117s - loss: 0.0187\n",
      "Epoch 16/25\n",
      " - 117s - loss: 0.0183\n",
      "Epoch 17/25\n",
      " - 117s - loss: 0.0176\n",
      "Epoch 18/25\n",
      " - 117s - loss: 0.0185\n",
      "Epoch 19/25\n",
      " - 117s - loss: 0.0176\n",
      "Epoch 20/25\n",
      " - 117s - loss: 0.0175\n",
      "Epoch 21/25\n",
      " - 117s - loss: 0.0174\n",
      "Epoch 22/25\n",
      " - 117s - loss: 0.0178\n",
      "Epoch 23/25\n",
      " - 117s - loss: 0.0178\n",
      "Epoch 24/25\n",
      " - 117s - loss: 0.0173\n",
      "Epoch 25/25\n",
      " - 117s - loss: 0.0174\n"
     ]
    }
   ],
   "source": [
    "# VGG16 with augmentation\n",
    "\n",
    "hist_aug = model.fit_generator(BatchGenerator_withaug(fetcher),\n",
    "                    samples_per_epoch=steps_to_take*3, \n",
    "                    nb_epoch=25,\n",
    "                    verbose=2,\n",
    "                    callbacks=[hist,checkpointer,early_stopping],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ab71c966748>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(hist_aug.history.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61578"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fetcher.training_images_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 116s - loss: 0.0173\n",
      "Epoch 2/50\n",
      " - 116s - loss: 0.0170\n",
      "Epoch 3/50\n",
      " - 116s - loss: 0.0163\n",
      "Epoch 4/50\n",
      " - 116s - loss: 0.0166\n",
      "Epoch 5/50\n",
      " - 116s - loss: 0.0168\n",
      "Epoch 6/50\n",
      " - 116s - loss: 0.0169\n",
      "Epoch 7/50\n",
      " - 116s - loss: 0.0168\n",
      "Epoch 8/50\n",
      " - 117s - loss: 0.0165\n",
      "Epoch 9/50\n",
      " - 116s - loss: 0.0164\n",
      "Epoch 10/50\n",
      " - 116s - loss: 0.0167\n",
      "Epoch 11/50\n",
      " - 116s - loss: 0.0163\n",
      "Epoch 12/50\n",
      " - 116s - loss: 0.0161\n",
      "Epoch 13/50\n",
      " - 116s - loss: 0.0164\n",
      "Epoch 14/50\n",
      " - 116s - loss: 0.0164\n",
      "Epoch 15/50\n",
      " - 116s - loss: 0.0165\n",
      "Epoch 16/50\n",
      " - 116s - loss: 0.0160\n",
      "Epoch 17/50\n",
      " - 116s - loss: 0.0155\n",
      "Epoch 18/50\n",
      " - 116s - loss: 0.0164\n",
      "Epoch 19/50\n",
      " - 116s - loss: 0.0156\n",
      "Epoch 20/50\n",
      " - 116s - loss: 0.0158\n",
      "Epoch 21/50\n",
      " - 116s - loss: 0.0155\n",
      "Epoch 22/50\n",
      " - 116s - loss: 0.0162\n",
      "Epoch 23/50\n",
      " - 116s - loss: 0.0161\n",
      "Epoch 24/50\n",
      " - 116s - loss: 0.0156\n",
      "Epoch 25/50\n",
      " - 116s - loss: 0.0158\n",
      "Epoch 26/50\n",
      " - 118s - loss: 0.0153\n",
      "Epoch 27/50\n",
      " - 122s - loss: 0.0158\n",
      "Epoch 28/50\n",
      " - 133s - loss: 0.0155\n",
      "Epoch 29/50\n",
      " - 123s - loss: 0.0160\n",
      "Epoch 30/50\n",
      " - 120s - loss: 0.0154\n",
      "Epoch 31/50\n",
      " - 117s - loss: 0.0150\n",
      "Epoch 32/50\n",
      " - 117s - loss: 0.0151\n",
      "Epoch 33/50\n",
      " - 117s - loss: 0.0155\n",
      "Epoch 34/50\n",
      " - 116s - loss: 0.0153\n",
      "Epoch 35/50\n",
      " - 116s - loss: 0.0149\n",
      "Epoch 36/50\n",
      " - 116s - loss: 0.0150\n",
      "Epoch 37/50\n",
      " - 116s - loss: 0.0151\n",
      "Epoch 38/50\n",
      " - 116s - loss: 0.0152\n",
      "Epoch 39/50\n",
      " - 116s - loss: 0.0155\n",
      "Epoch 40/50\n",
      " - 116s - loss: 0.0150\n",
      "Epoch 41/50\n",
      " - 116s - loss: 0.0150\n",
      "Epoch 42/50\n",
      " - 116s - loss: 0.0154\n",
      "Epoch 43/50\n",
      " - 116s - loss: 0.0150\n",
      "Epoch 44/50\n",
      " - 116s - loss: 0.0147\n",
      "Epoch 45/50\n",
      " - 116s - loss: 0.0149\n",
      "Epoch 46/50\n",
      " - 116s - loss: 0.0151\n",
      "Epoch 47/50\n",
      " - 116s - loss: 0.0150\n",
      "Epoch 48/50\n",
      " - 116s - loss: 0.0149\n",
      "Epoch 49/50\n",
      " - 116s - loss: 0.0144\n",
      "Epoch 50/50\n",
      " - 116s - loss: 0.0150\n"
     ]
    }
   ],
   "source": [
    "#Aug with larger epochs\n",
    "\n",
    "hist_aug2 = model.fit_generator(BatchGenerator_withaug(fetcher),\n",
    "                    samples_per_epoch=steps_to_take*3, \n",
    "                    nb_epoch=50,\n",
    "                    verbose=2,\n",
    "                    callbacks=[hist,checkpointer,early_stopping],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./tmp/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testGenerator(getter):\n",
    "    while 1:\n",
    "        for f in getter.test_images_paths:\n",
    "            X_test = process_images([getter.test_path + '/' + fname for fname in [f]])\n",
    "            yield (X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(testGenerator(fetcher),\n",
    "                       val_samples = len(fetcher.test_images_paths),\n",
    "                        max_q_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 37)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = open('all_zeros_benchmark.csv','r').readlines()[0]\n",
    "\n",
    "with open('submission_1.csv','w') as outfile:\n",
    "    outfile.write(header)\n",
    "    for i in range(len(fetcher.test_images_paths)):\n",
    "        id_ = (fetcher.get_id(fetcher.test_images_paths[i]))\n",
    "        pred = predictions[i]\n",
    "        outline = id_ + \",\" + \",\".join([str(x) for x in pred])\n",
    "        outfile.write(outline + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Model):\n",
    "    def __init__(self, input_shape=(3, 106, 106), num_classes=37):\n",
    "        # super(LeNet, self).__init__(name=\"LeNet\")\n",
    "        self.num_classes = num_classes\n",
    "        ''' 定义要用到的层 layers '''\n",
    "        # 输入层\n",
    "        img_input = Input(shape=input_shape)\n",
    "\n",
    "        # Conv => ReLu => Pool\n",
    "        x = Conv2D(filters=20, kernel_size=5, padding=\"same\", activation=\"relu\" ,name='block1_conv1')(img_input)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "        # Conv => ReLu => Pool\n",
    "        x = Conv2D(filters=50, kernel_size=5, padding=\"same\", activation=\"relu\", name='block1_conv2')(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\", name='block1_poo2')(x)\n",
    "        # 压成一维\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        # 全连接层\n",
    "        x = Dense(units=500, activation=\"relu\", name=\"f1\")(x)\n",
    "        # softmax分类器\n",
    "        x = Dense(units=num_classes, activation=\"softmax\", name=\"prediction\")(x)\n",
    "\n",
    "        # 调用Model类的Model(input, output, name=\"***\")构造方法\n",
    "        super(LeNet, self).__init__(img_input, x, name=\"LeNet\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # 前向传播计算\n",
    "        # 使用在__init__方法中定义的层\n",
    "        return self.output(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (3,106,106)\n",
    "classes = 37\n",
    "\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 64\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT = 0.2\n",
    "IMG_ROWS, IMG_COLS = 106, 106\n",
    "NB_CLASSES = 37\n",
    "INPUT_SHAPE = (3, IMG_ROWS, IMG_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_generator(getter):\n",
    "    while 1:\n",
    "        for f in getter.training_images_paths:\n",
    "            X_train = process_images([getter.train_path + '/' + fname for fname in [f]])\n",
    "            yield X_train\n",
    "            \n",
    "def y_generator(getter):\n",
    "    while 1:\n",
    "        for f in getter.training_images_paths:\n",
    "            id_ = getter.get_id(f)\n",
    "            y_train = np.array(getter.find_label(id_))\n",
    "            y_train = np.reshape(y_train, (1,37))\n",
    "            yield y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-50381a88c258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLeModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNB_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mLeModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m LeModel.compile(loss=\"categorical_crossentropy\", optimizer=tf.train.RMSPropOptimizer(learning_rate=0.0001),\n\u001b[1;32m      5\u001b[0m               metrics=[\"accuracy\"])\n",
      "\u001b[0;32m<ipython-input-58-ec88fde04119>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, num_classes)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# 调用Model类的Model(input, output, name=\"***\")构造方法\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLeNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LeNet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "LeModel = LeNet(INPUT_SHAPE, NB_CLASSES)\n",
    "LeModel.summary()\n",
    "\n",
    "LeModel.compile(loss=\"categorical_crossentropy\", optimizer=tf.train.RMSPropOptimizer(learning_rate=0.0001),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = LeModel.fit(x=X_generator(fetcher), y=X_generator, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE,\n",
    "                    validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
